{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import mixture\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 365610 entries, 0 to 365609\n",
      "Data columns (total 33 columns):\n",
      "norm_likes                365610 non-null float64\n",
      "norm_views                365610 non-null float64\n",
      "norm_comments             365610 non-null float64\n",
      "norm_user_views           365610 non-null float64\n",
      "norm_user_comments        365610 non-null float64\n",
      "norm_country_views        365610 non-null float64\n",
      "norm_country_comments     365610 non-null float64\n",
      "norm_category_views       365610 non-null float64\n",
      "norm_category_comments    365610 non-null float64\n",
      "cat1                      365610 non-null float64\n",
      "cat2                      365610 non-null float64\n",
      "cat3                      365610 non-null float64\n",
      "cat4                      365610 non-null float64\n",
      "cat5                      365610 non-null float64\n",
      "cat6                      365610 non-null float64\n",
      "cat7                      365610 non-null float64\n",
      "cat8                      365610 non-null float64\n",
      "cat9                      365610 non-null float64\n",
      "count1                    365610 non-null float64\n",
      "count2                    365610 non-null float64\n",
      "count3                    365610 non-null float64\n",
      "count4                    365610 non-null float64\n",
      "count5                    365610 non-null float64\n",
      "count6                    365610 non-null float64\n",
      "count7                    365610 non-null float64\n",
      "count8                    365610 non-null float64\n",
      "count9                    365610 non-null float64\n",
      "count10                   365610 non-null float64\n",
      "count11                   365610 non-null float64\n",
      "count12                   365610 non-null float64\n",
      "count13                   365610 non-null float64\n",
      "count14                   365610 non-null float64\n",
      "count15                   365610 non-null float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 92.0 MB\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"data/training_data_with_features.csv\")\n",
    "df = training_data[[\"norm_likes\", \"norm_views\", \"norm_comments\", \"norm_user_views\", \"norm_user_comments\",\n",
    "               \"norm_country_views\", \"norm_country_comments\", \"norm_category_views\", \"norm_category_comments\", \n",
    "               \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\", \"count1\", \"count2\", \n",
    "               \"count3\", \"count4\", \"count5\", \"count6\", \"count7\", \"count8\", \"count9\", \"count10\", \"count11\", \n",
    "               \"count12\", \"count13\", \"count14\", \"count15\"]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_likes</th>\n",
       "      <th>norm_views</th>\n",
       "      <th>norm_comments</th>\n",
       "      <th>norm_user_views</th>\n",
       "      <th>norm_user_comments</th>\n",
       "      <th>norm_country_views</th>\n",
       "      <th>norm_country_comments</th>\n",
       "      <th>norm_category_views</th>\n",
       "      <th>norm_category_comments</th>\n",
       "      <th>cat1</th>\n",
       "      <th>...</th>\n",
       "      <th>count6</th>\n",
       "      <th>count7</th>\n",
       "      <th>count8</th>\n",
       "      <th>count9</th>\n",
       "      <th>count10</th>\n",
       "      <th>count11</th>\n",
       "      <th>count12</th>\n",
       "      <th>count13</th>\n",
       "      <th>count14</th>\n",
       "      <th>count15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>norm_likes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655375</td>\n",
       "      <td>0.734362</td>\n",
       "      <td>0.606205</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.037816</td>\n",
       "      <td>0.056353</td>\n",
       "      <td>0.148829</td>\n",
       "      <td>0.196442</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032142</td>\n",
       "      <td>-0.005806</td>\n",
       "      <td>-0.024928</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>-0.037125</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>-0.016722</td>\n",
       "      <td>-0.014527</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.043862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_views</td>\n",
       "      <td>0.655375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.544742</td>\n",
       "      <td>0.804420</td>\n",
       "      <td>0.498912</td>\n",
       "      <td>0.148362</td>\n",
       "      <td>0.127913</td>\n",
       "      <td>0.190202</td>\n",
       "      <td>0.115225</td>\n",
       "      <td>-0.050575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041717</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>-0.018762</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>0.061235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_comments</td>\n",
       "      <td>0.734362</td>\n",
       "      <td>0.544742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516704</td>\n",
       "      <td>0.833106</td>\n",
       "      <td>0.111656</td>\n",
       "      <td>0.129506</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>0.157516</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042124</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>-0.012594</td>\n",
       "      <td>-0.045726</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>0.069015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_user_views</td>\n",
       "      <td>0.606205</td>\n",
       "      <td>0.804420</td>\n",
       "      <td>0.516704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620214</td>\n",
       "      <td>0.183697</td>\n",
       "      <td>0.161532</td>\n",
       "      <td>0.223578</td>\n",
       "      <td>0.129783</td>\n",
       "      <td>-0.059416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053814</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>0.042473</td>\n",
       "      <td>-0.051210</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.082779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_user_comments</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.498912</td>\n",
       "      <td>0.833106</td>\n",
       "      <td>0.620214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>0.157540</td>\n",
       "      <td>0.101224</td>\n",
       "      <td>0.175487</td>\n",
       "      <td>0.042145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051103</td>\n",
       "      <td>0.033624</td>\n",
       "      <td>-0.015017</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>-0.056414</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>-0.022553</td>\n",
       "      <td>0.051486</td>\n",
       "      <td>0.085118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_country_views</td>\n",
       "      <td>0.037816</td>\n",
       "      <td>0.148362</td>\n",
       "      <td>0.111656</td>\n",
       "      <td>0.183697</td>\n",
       "      <td>0.133896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862168</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.029435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281184</td>\n",
       "      <td>0.075685</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.198719</td>\n",
       "      <td>-0.265177</td>\n",
       "      <td>-0.126462</td>\n",
       "      <td>0.128750</td>\n",
       "      <td>0.048208</td>\n",
       "      <td>0.121072</td>\n",
       "      <td>0.412740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_country_comments</td>\n",
       "      <td>0.056353</td>\n",
       "      <td>0.127913</td>\n",
       "      <td>0.129506</td>\n",
       "      <td>0.161532</td>\n",
       "      <td>0.157540</td>\n",
       "      <td>0.862168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006312</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.041745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325265</td>\n",
       "      <td>0.179229</td>\n",
       "      <td>-0.095952</td>\n",
       "      <td>-0.097245</td>\n",
       "      <td>-0.353077</td>\n",
       "      <td>-0.007563</td>\n",
       "      <td>0.082012</td>\n",
       "      <td>-0.135667</td>\n",
       "      <td>0.300688</td>\n",
       "      <td>0.532907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_category_views</td>\n",
       "      <td>0.148829</td>\n",
       "      <td>0.190202</td>\n",
       "      <td>0.095424</td>\n",
       "      <td>0.223578</td>\n",
       "      <td>0.101224</td>\n",
       "      <td>0.027390</td>\n",
       "      <td>-0.006312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605805</td>\n",
       "      <td>-0.265902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012638</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.069049</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>-0.006177</td>\n",
       "      <td>-0.022412</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>-0.002703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_category_comments</td>\n",
       "      <td>0.196442</td>\n",
       "      <td>0.115225</td>\n",
       "      <td>0.157516</td>\n",
       "      <td>0.129783</td>\n",
       "      <td>0.175487</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.605805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>-0.030183</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>-0.034735</td>\n",
       "      <td>-0.020915</td>\n",
       "      <td>0.039006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat1</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>-0.050575</td>\n",
       "      <td>0.028484</td>\n",
       "      <td>-0.059416</td>\n",
       "      <td>0.042145</td>\n",
       "      <td>0.029435</td>\n",
       "      <td>0.041745</td>\n",
       "      <td>-0.265902</td>\n",
       "      <td>0.180833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>-0.010167</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>-0.052171</td>\n",
       "      <td>-0.011687</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.021975</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat2</td>\n",
       "      <td>-0.097718</td>\n",
       "      <td>-0.045437</td>\n",
       "      <td>-0.088882</td>\n",
       "      <td>-0.054908</td>\n",
       "      <td>-0.103801</td>\n",
       "      <td>-0.024644</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>-0.238888</td>\n",
       "      <td>-0.564274</td>\n",
       "      <td>-0.147579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.013288</td>\n",
       "      <td>-0.025796</td>\n",
       "      <td>0.023067</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>-0.008516</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>-0.021659</td>\n",
       "      <td>-0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat3</td>\n",
       "      <td>0.047511</td>\n",
       "      <td>0.097802</td>\n",
       "      <td>0.064639</td>\n",
       "      <td>0.109286</td>\n",
       "      <td>0.060217</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>-0.007799</td>\n",
       "      <td>0.514201</td>\n",
       "      <td>0.410365</td>\n",
       "      <td>-0.244250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005145</td>\n",
       "      <td>-0.018799</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.054269</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>-0.007086</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>-0.032833</td>\n",
       "      <td>0.018743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat4</td>\n",
       "      <td>-0.074704</td>\n",
       "      <td>-0.087682</td>\n",
       "      <td>-0.061510</td>\n",
       "      <td>-0.097661</td>\n",
       "      <td>-0.065964</td>\n",
       "      <td>-0.035545</td>\n",
       "      <td>-0.010556</td>\n",
       "      <td>-0.460993</td>\n",
       "      <td>-0.390496</td>\n",
       "      <td>-0.145881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009416</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>-0.015858</td>\n",
       "      <td>-0.030498</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>-0.008932</td>\n",
       "      <td>-0.010872</td>\n",
       "      <td>0.021122</td>\n",
       "      <td>-0.019267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat5</td>\n",
       "      <td>0.162398</td>\n",
       "      <td>0.100277</td>\n",
       "      <td>0.079684</td>\n",
       "      <td>0.122621</td>\n",
       "      <td>0.094124</td>\n",
       "      <td>-0.048366</td>\n",
       "      <td>-0.030124</td>\n",
       "      <td>0.527211</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>-0.075583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>-0.028295</td>\n",
       "      <td>0.031253</td>\n",
       "      <td>-0.021815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat6</td>\n",
       "      <td>-0.035151</td>\n",
       "      <td>-0.028452</td>\n",
       "      <td>-0.024603</td>\n",
       "      <td>-0.025703</td>\n",
       "      <td>-0.025788</td>\n",
       "      <td>-0.018425</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>-0.149586</td>\n",
       "      <td>-0.156190</td>\n",
       "      <td>-0.106298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013276</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>-0.007514</td>\n",
       "      <td>-0.023791</td>\n",
       "      <td>-0.062613</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.020171</td>\n",
       "      <td>-0.018439</td>\n",
       "      <td>0.062619</td>\n",
       "      <td>-0.031540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat7</td>\n",
       "      <td>-0.018590</td>\n",
       "      <td>0.078053</td>\n",
       "      <td>-0.043324</td>\n",
       "      <td>0.099164</td>\n",
       "      <td>-0.046924</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>0.410371</td>\n",
       "      <td>-0.275043</td>\n",
       "      <td>-0.117750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025515</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>-0.020952</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>-0.016639</td>\n",
       "      <td>-0.029024</td>\n",
       "      <td>-0.019533</td>\n",
       "      <td>0.052735</td>\n",
       "      <td>0.034628</td>\n",
       "      <td>-0.029232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat8</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.044415</td>\n",
       "      <td>-0.004647</td>\n",
       "      <td>0.045487</td>\n",
       "      <td>0.029897</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.017651</td>\n",
       "      <td>0.281969</td>\n",
       "      <td>-0.178404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001507</td>\n",
       "      <td>-0.023121</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.047131</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>-0.010500</td>\n",
       "      <td>-0.028443</td>\n",
       "      <td>0.038145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat9</td>\n",
       "      <td>-0.025860</td>\n",
       "      <td>-0.043774</td>\n",
       "      <td>-0.016237</td>\n",
       "      <td>-0.052033</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>-0.039372</td>\n",
       "      <td>-0.025189</td>\n",
       "      <td>-0.230143</td>\n",
       "      <td>-0.103081</td>\n",
       "      <td>-0.156628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>-0.013911</td>\n",
       "      <td>-0.016610</td>\n",
       "      <td>0.008925</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>-0.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count1</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.064650</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.075167</td>\n",
       "      <td>0.030339</td>\n",
       "      <td>0.435762</td>\n",
       "      <td>0.224075</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>-0.008142</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072439</td>\n",
       "      <td>-0.083043</td>\n",
       "      <td>-0.058781</td>\n",
       "      <td>-0.038796</td>\n",
       "      <td>-0.070021</td>\n",
       "      <td>-0.073571</td>\n",
       "      <td>-0.067175</td>\n",
       "      <td>-0.075675</td>\n",
       "      <td>-0.084200</td>\n",
       "      <td>-0.059835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count2</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.053484</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.054519</td>\n",
       "      <td>0.057115</td>\n",
       "      <td>0.360498</td>\n",
       "      <td>0.390830</td>\n",
       "      <td>-0.019303</td>\n",
       "      <td>-0.006557</td>\n",
       "      <td>0.021286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077772</td>\n",
       "      <td>-0.089156</td>\n",
       "      <td>-0.063108</td>\n",
       "      <td>-0.041652</td>\n",
       "      <td>-0.075176</td>\n",
       "      <td>-0.078988</td>\n",
       "      <td>-0.072120</td>\n",
       "      <td>-0.081247</td>\n",
       "      <td>-0.090399</td>\n",
       "      <td>-0.064240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count3</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>-0.071934</td>\n",
       "      <td>-0.041518</td>\n",
       "      <td>-0.087731</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>-0.484858</td>\n",
       "      <td>-0.320587</td>\n",
       "      <td>-0.024954</td>\n",
       "      <td>-0.015250</td>\n",
       "      <td>-0.017385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081410</td>\n",
       "      <td>-0.093328</td>\n",
       "      <td>-0.066061</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>-0.078693</td>\n",
       "      <td>-0.082684</td>\n",
       "      <td>-0.075494</td>\n",
       "      <td>-0.085048</td>\n",
       "      <td>-0.094629</td>\n",
       "      <td>-0.067246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count4</td>\n",
       "      <td>-0.036046</td>\n",
       "      <td>-0.040383</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.051146</td>\n",
       "      <td>-0.043618</td>\n",
       "      <td>-0.272193</td>\n",
       "      <td>-0.273882</td>\n",
       "      <td>-0.000952</td>\n",
       "      <td>-0.013749</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080225</td>\n",
       "      <td>-0.091970</td>\n",
       "      <td>-0.065099</td>\n",
       "      <td>-0.042966</td>\n",
       "      <td>-0.077548</td>\n",
       "      <td>-0.081480</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>-0.083810</td>\n",
       "      <td>-0.093251</td>\n",
       "      <td>-0.066267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count5</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>-0.025659</td>\n",
       "      <td>-0.013363</td>\n",
       "      <td>-0.032834</td>\n",
       "      <td>-0.016504</td>\n",
       "      <td>-0.172946</td>\n",
       "      <td>-0.103187</td>\n",
       "      <td>-0.001848</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073511</td>\n",
       "      <td>-0.084273</td>\n",
       "      <td>-0.059651</td>\n",
       "      <td>-0.039370</td>\n",
       "      <td>-0.071058</td>\n",
       "      <td>-0.074661</td>\n",
       "      <td>-0.068169</td>\n",
       "      <td>-0.076796</td>\n",
       "      <td>-0.085447</td>\n",
       "      <td>-0.060721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count6</td>\n",
       "      <td>-0.032142</td>\n",
       "      <td>-0.041717</td>\n",
       "      <td>-0.042124</td>\n",
       "      <td>-0.053814</td>\n",
       "      <td>-0.051103</td>\n",
       "      <td>-0.281184</td>\n",
       "      <td>-0.325265</td>\n",
       "      <td>-0.012638</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082724</td>\n",
       "      <td>-0.058555</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>-0.069752</td>\n",
       "      <td>-0.073289</td>\n",
       "      <td>-0.066917</td>\n",
       "      <td>-0.075385</td>\n",
       "      <td>-0.083877</td>\n",
       "      <td>-0.059605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count7</td>\n",
       "      <td>-0.005806</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>0.033624</td>\n",
       "      <td>0.075685</td>\n",
       "      <td>0.179229</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.030183</td>\n",
       "      <td>-0.010167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067127</td>\n",
       "      <td>-0.044305</td>\n",
       "      <td>-0.079963</td>\n",
       "      <td>-0.084018</td>\n",
       "      <td>-0.076713</td>\n",
       "      <td>-0.086420</td>\n",
       "      <td>-0.096156</td>\n",
       "      <td>-0.068331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count8</td>\n",
       "      <td>-0.024928</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>-0.015017</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>-0.095952</td>\n",
       "      <td>0.019065</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058555</td>\n",
       "      <td>-0.067127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>-0.056601</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.054300</td>\n",
       "      <td>-0.061172</td>\n",
       "      <td>-0.068063</td>\n",
       "      <td>-0.048367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count9</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>-0.012594</td>\n",
       "      <td>0.042473</td>\n",
       "      <td>-0.012939</td>\n",
       "      <td>0.198719</td>\n",
       "      <td>-0.097245</td>\n",
       "      <td>0.069049</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>-0.052171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038647</td>\n",
       "      <td>-0.044305</td>\n",
       "      <td>-0.031360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037357</td>\n",
       "      <td>-0.039251</td>\n",
       "      <td>-0.035839</td>\n",
       "      <td>-0.040374</td>\n",
       "      <td>-0.044922</td>\n",
       "      <td>-0.031923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count10</td>\n",
       "      <td>-0.037125</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>-0.045726</td>\n",
       "      <td>-0.051210</td>\n",
       "      <td>-0.056414</td>\n",
       "      <td>-0.265177</td>\n",
       "      <td>-0.353077</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>-0.011687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069752</td>\n",
       "      <td>-0.079963</td>\n",
       "      <td>-0.056601</td>\n",
       "      <td>-0.037357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070843</td>\n",
       "      <td>-0.064684</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-0.081078</td>\n",
       "      <td>-0.057616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count11</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>-0.018762</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.126462</td>\n",
       "      <td>-0.007563</td>\n",
       "      <td>-0.006177</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073289</td>\n",
       "      <td>-0.084018</td>\n",
       "      <td>-0.059471</td>\n",
       "      <td>-0.039251</td>\n",
       "      <td>-0.070843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067963</td>\n",
       "      <td>-0.076564</td>\n",
       "      <td>-0.085189</td>\n",
       "      <td>-0.060538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count12</td>\n",
       "      <td>-0.016722</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.016879</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.128750</td>\n",
       "      <td>0.082012</td>\n",
       "      <td>-0.022412</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066917</td>\n",
       "      <td>-0.076713</td>\n",
       "      <td>-0.054300</td>\n",
       "      <td>-0.035839</td>\n",
       "      <td>-0.064684</td>\n",
       "      <td>-0.067963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069907</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>-0.055274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count13</td>\n",
       "      <td>-0.014527</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-0.022553</td>\n",
       "      <td>0.048208</td>\n",
       "      <td>-0.135667</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>-0.034735</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075385</td>\n",
       "      <td>-0.086420</td>\n",
       "      <td>-0.061172</td>\n",
       "      <td>-0.040374</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-0.076564</td>\n",
       "      <td>-0.069907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087625</td>\n",
       "      <td>-0.062269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count14</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.017962</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.051486</td>\n",
       "      <td>0.121072</td>\n",
       "      <td>0.300688</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>-0.020915</td>\n",
       "      <td>-0.021975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083877</td>\n",
       "      <td>-0.096156</td>\n",
       "      <td>-0.068063</td>\n",
       "      <td>-0.044922</td>\n",
       "      <td>-0.081078</td>\n",
       "      <td>-0.085189</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>-0.087625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count15</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>0.069015</td>\n",
       "      <td>0.082779</td>\n",
       "      <td>0.085118</td>\n",
       "      <td>0.412740</td>\n",
       "      <td>0.532907</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.039006</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059605</td>\n",
       "      <td>-0.068331</td>\n",
       "      <td>-0.048367</td>\n",
       "      <td>-0.031923</td>\n",
       "      <td>-0.057616</td>\n",
       "      <td>-0.060538</td>\n",
       "      <td>-0.055274</td>\n",
       "      <td>-0.062269</td>\n",
       "      <td>-0.069283</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        norm_likes  norm_views  norm_comments  \\\n",
       "norm_likes                1.000000    0.655375       0.734362   \n",
       "norm_views                0.655375    1.000000       0.544742   \n",
       "norm_comments             0.734362    0.544742       1.000000   \n",
       "norm_user_views           0.606205    0.804420       0.516704   \n",
       "norm_user_comments        0.705128    0.498912       0.833106   \n",
       "norm_country_views        0.037816    0.148362       0.111656   \n",
       "norm_country_comments     0.056353    0.127913       0.129506   \n",
       "norm_category_views       0.148829    0.190202       0.095424   \n",
       "norm_category_comments    0.196442    0.115225       0.157516   \n",
       "cat1                      0.038968   -0.050575       0.028484   \n",
       "cat2                     -0.097718   -0.045437      -0.088882   \n",
       "cat3                      0.047511    0.097802       0.064639   \n",
       "cat4                     -0.074704   -0.087682      -0.061510   \n",
       "cat5                      0.162398    0.100277       0.079684   \n",
       "cat6                     -0.035151   -0.028452      -0.024603   \n",
       "cat7                     -0.018590    0.078053      -0.043324   \n",
       "cat8                      0.031425    0.003357       0.044415   \n",
       "cat9                     -0.025860   -0.043774      -0.016237   \n",
       "count1                    0.026419    0.064650       0.029019   \n",
       "count2                    0.021757    0.053484       0.050615   \n",
       "count3                    0.042828   -0.071934      -0.041518   \n",
       "count4                   -0.036046   -0.040383      -0.035469   \n",
       "count5                    0.005300   -0.025659      -0.013363   \n",
       "count6                   -0.032142   -0.041717      -0.042124   \n",
       "count7                   -0.005806    0.011229       0.023211   \n",
       "count8                   -0.024928    0.000502      -0.012426   \n",
       "count9                    0.003300    0.029482      -0.012594   \n",
       "count10                  -0.037125   -0.039342      -0.045726   \n",
       "count11                   0.018637   -0.018762      -0.000979   \n",
       "count12                  -0.016722    0.019102       0.010621   \n",
       "count13                  -0.014527    0.007152      -0.017570   \n",
       "count14                   0.004662    0.017962       0.038941   \n",
       "count15                   0.043862    0.061235       0.069015   \n",
       "\n",
       "                        norm_user_views  norm_user_comments  \\\n",
       "norm_likes                     0.606205            0.705128   \n",
       "norm_views                     0.804420            0.498912   \n",
       "norm_comments                  0.516704            0.833106   \n",
       "norm_user_views                1.000000            0.620214   \n",
       "norm_user_comments             0.620214            1.000000   \n",
       "norm_country_views             0.183697            0.133896   \n",
       "norm_country_comments          0.161532            0.157540   \n",
       "norm_category_views            0.223578            0.101224   \n",
       "norm_category_comments         0.129783            0.175487   \n",
       "cat1                          -0.059416            0.042145   \n",
       "cat2                          -0.054908           -0.103801   \n",
       "cat3                           0.109286            0.060217   \n",
       "cat4                          -0.097661           -0.065964   \n",
       "cat5                           0.122621            0.094124   \n",
       "cat6                          -0.025703           -0.025788   \n",
       "cat7                           0.099164           -0.046924   \n",
       "cat8                          -0.004647            0.045487   \n",
       "cat9                          -0.052033           -0.012935   \n",
       "count1                         0.075167            0.030339   \n",
       "count2                         0.054519            0.057115   \n",
       "count3                        -0.087731           -0.050259   \n",
       "count4                        -0.051146           -0.043618   \n",
       "count5                        -0.032834           -0.016504   \n",
       "count6                        -0.053814           -0.051103   \n",
       "count7                         0.024338            0.033624   \n",
       "count8                        -0.000661           -0.015017   \n",
       "count9                         0.042473           -0.012939   \n",
       "count10                       -0.051210           -0.056414   \n",
       "count11                       -0.023597           -0.000387   \n",
       "count12                        0.016879            0.010927   \n",
       "count13                        0.008019           -0.022553   \n",
       "count14                        0.031500            0.051486   \n",
       "count15                        0.082779            0.085118   \n",
       "\n",
       "                        norm_country_views  norm_country_comments  \\\n",
       "norm_likes                        0.037816               0.056353   \n",
       "norm_views                        0.148362               0.127913   \n",
       "norm_comments                     0.111656               0.129506   \n",
       "norm_user_views                   0.183697               0.161532   \n",
       "norm_user_comments                0.133896               0.157540   \n",
       "norm_country_views                1.000000               0.862168   \n",
       "norm_country_comments             0.862168               1.000000   \n",
       "norm_category_views               0.027390              -0.006312   \n",
       "norm_category_comments            0.012864               0.002475   \n",
       "cat1                              0.029435               0.041745   \n",
       "cat2                             -0.024644              -0.026313   \n",
       "cat3                              0.020873              -0.007799   \n",
       "cat4                             -0.035545              -0.010556   \n",
       "cat5                             -0.048366              -0.030124   \n",
       "cat6                             -0.018425               0.015792   \n",
       "cat7                              0.050481               0.021932   \n",
       "cat8                              0.029897               0.008239   \n",
       "cat9                             -0.039372              -0.025189   \n",
       "count1                            0.435762               0.224075   \n",
       "count2                            0.360498               0.390830   \n",
       "count3                           -0.484858              -0.320587   \n",
       "count4                           -0.272193              -0.273882   \n",
       "count5                           -0.172946              -0.103187   \n",
       "count6                           -0.281184              -0.325265   \n",
       "count7                            0.075685               0.179229   \n",
       "count8                            0.003387              -0.095952   \n",
       "count9                            0.198719              -0.097245   \n",
       "count10                          -0.265177              -0.353077   \n",
       "count11                          -0.126462              -0.007563   \n",
       "count12                           0.128750               0.082012   \n",
       "count13                           0.048208              -0.135667   \n",
       "count14                           0.121072               0.300688   \n",
       "count15                           0.412740               0.532907   \n",
       "\n",
       "                        norm_category_views  norm_category_comments      cat1  \\\n",
       "norm_likes                         0.148829                0.196442  0.038968   \n",
       "norm_views                         0.190202                0.115225 -0.050575   \n",
       "norm_comments                      0.095424                0.157516  0.028484   \n",
       "norm_user_views                    0.223578                0.129783 -0.059416   \n",
       "norm_user_comments                 0.101224                0.175487  0.042145   \n",
       "norm_country_views                 0.027390                0.012864  0.029435   \n",
       "norm_country_comments             -0.006312                0.002475  0.041745   \n",
       "norm_category_views                1.000000                0.605805 -0.265902   \n",
       "norm_category_comments             0.605805                1.000000  0.180833   \n",
       "cat1                              -0.265902                0.180833  1.000000   \n",
       "cat2                              -0.238888               -0.564274 -0.147579   \n",
       "cat3                               0.514201                0.410365 -0.244250   \n",
       "cat4                              -0.460993               -0.390496 -0.145881   \n",
       "cat5                               0.527211                0.505878 -0.075583   \n",
       "cat6                              -0.149586               -0.156190 -0.106298   \n",
       "cat7                               0.410371               -0.275043 -0.117750   \n",
       "cat8                               0.017651                0.281969 -0.178404   \n",
       "cat9                              -0.230143               -0.103081 -0.156628   \n",
       "count1                             0.025225               -0.008142  0.012509   \n",
       "count2                            -0.019303               -0.006557  0.021286   \n",
       "count3                            -0.024954               -0.015250 -0.017385   \n",
       "count4                            -0.000952               -0.013749 -0.020821   \n",
       "count5                            -0.001848                0.020856  0.009501   \n",
       "count6                            -0.012638                0.007802  0.013491   \n",
       "count7                            -0.011808               -0.030183 -0.010167   \n",
       "count8                             0.019065                0.038959  0.004187   \n",
       "count9                             0.069049                0.039360 -0.052171   \n",
       "count10                            0.008500                0.010018 -0.011687   \n",
       "count11                           -0.006177                0.012251  0.003551   \n",
       "count12                           -0.022412                0.002394  0.024837   \n",
       "count13                            0.011928               -0.034735 -0.006892   \n",
       "count14                            0.005227               -0.020915 -0.021975   \n",
       "count15                           -0.002703                0.039006  0.044485   \n",
       "\n",
       "                        ...    count6    count7    count8    count9   count10  \\\n",
       "norm_likes              ... -0.032142 -0.005806 -0.024928  0.003300 -0.037125   \n",
       "norm_views              ... -0.041717  0.011229  0.000502  0.029482 -0.039342   \n",
       "norm_comments           ... -0.042124  0.023211 -0.012426 -0.012594 -0.045726   \n",
       "norm_user_views         ... -0.053814  0.024338 -0.000661  0.042473 -0.051210   \n",
       "norm_user_comments      ... -0.051103  0.033624 -0.015017 -0.012939 -0.056414   \n",
       "norm_country_views      ... -0.281184  0.075685  0.003387  0.198719 -0.265177   \n",
       "norm_country_comments   ... -0.325265  0.179229 -0.095952 -0.097245 -0.353077   \n",
       "norm_category_views     ... -0.012638 -0.011808  0.019065  0.069049  0.008500   \n",
       "norm_category_comments  ...  0.007802 -0.030183  0.038959  0.039360  0.010018   \n",
       "cat1                    ...  0.013491 -0.010167  0.004187 -0.052171 -0.011687   \n",
       "cat2                    ...  0.005734 -0.001343 -0.013288 -0.025796  0.023067   \n",
       "cat3                    ... -0.005145 -0.018799  0.019089  0.054269  0.021207   \n",
       "cat4                    ...  0.009416  0.017874 -0.015858 -0.030498 -0.000467   \n",
       "cat5                    ...  0.011488 -0.001249  0.013289 -0.003696  0.002936   \n",
       "cat6                    ... -0.013276  0.034769 -0.007514 -0.023791 -0.062613   \n",
       "cat7                    ... -0.025515  0.020164 -0.020952  0.032087 -0.016639   \n",
       "cat8                    ... -0.001507 -0.023121  0.023590  0.047131  0.010442   \n",
       "cat9                    ...  0.002104  0.006634 -0.013911 -0.016610  0.008925   \n",
       "count1                  ... -0.072439 -0.083043 -0.058781 -0.038796 -0.070021   \n",
       "count2                  ... -0.077772 -0.089156 -0.063108 -0.041652 -0.075176   \n",
       "count3                  ... -0.081410 -0.093328 -0.066061 -0.043601 -0.078693   \n",
       "count4                  ... -0.080225 -0.091970 -0.065099 -0.042966 -0.077548   \n",
       "count5                  ... -0.073511 -0.084273 -0.059651 -0.039370 -0.071058   \n",
       "count6                  ...  1.000000 -0.082724 -0.058555 -0.038647 -0.069752   \n",
       "count7                  ... -0.082724  1.000000 -0.067127 -0.044305 -0.079963   \n",
       "count8                  ... -0.058555 -0.067127  1.000000 -0.031360 -0.056601   \n",
       "count9                  ... -0.038647 -0.044305 -0.031360  1.000000 -0.037357   \n",
       "count10                 ... -0.069752 -0.079963 -0.056601 -0.037357  1.000000   \n",
       "count11                 ... -0.073289 -0.084018 -0.059471 -0.039251 -0.070843   \n",
       "count12                 ... -0.066917 -0.076713 -0.054300 -0.035839 -0.064684   \n",
       "count13                 ... -0.075385 -0.086420 -0.061172 -0.040374 -0.072869   \n",
       "count14                 ... -0.083877 -0.096156 -0.068063 -0.044922 -0.081078   \n",
       "count15                 ... -0.059605 -0.068331 -0.048367 -0.031923 -0.057616   \n",
       "\n",
       "                         count11   count12   count13   count14   count15  \n",
       "norm_likes              0.018637 -0.016722 -0.014527  0.004662  0.043862  \n",
       "norm_views             -0.018762  0.019102  0.007152  0.017962  0.061235  \n",
       "norm_comments          -0.000979  0.010621 -0.017570  0.038941  0.069015  \n",
       "norm_user_views        -0.023597  0.016879  0.008019  0.031500  0.082779  \n",
       "norm_user_comments     -0.000387  0.010927 -0.022553  0.051486  0.085118  \n",
       "norm_country_views     -0.126462  0.128750  0.048208  0.121072  0.412740  \n",
       "norm_country_comments  -0.007563  0.082012 -0.135667  0.300688  0.532907  \n",
       "norm_category_views    -0.006177 -0.022412  0.011928  0.005227 -0.002703  \n",
       "norm_category_comments  0.012251  0.002394 -0.034735 -0.020915  0.039006  \n",
       "cat1                    0.003551  0.024837 -0.006892 -0.021975  0.044485  \n",
       "cat2                    0.004199 -0.008516  0.023229 -0.021659 -0.011728  \n",
       "cat3                   -0.004990 -0.007086  0.002324 -0.032833  0.018743  \n",
       "cat4                    0.002781 -0.008932 -0.010872  0.021122 -0.019267  \n",
       "cat5                    0.024359 -0.014636 -0.028295  0.031253 -0.021815  \n",
       "cat6                    0.003790  0.020171 -0.018439  0.062619 -0.031540  \n",
       "cat7                   -0.029024 -0.019533  0.052735  0.034628 -0.029232  \n",
       "cat8                   -0.006337 -0.002727 -0.010500 -0.028443  0.038145  \n",
       "cat9                    0.010239  0.008633 -0.008791  0.012782 -0.032470  \n",
       "count1                 -0.073571 -0.067175 -0.075675 -0.084200 -0.059835  \n",
       "count2                 -0.078988 -0.072120 -0.081247 -0.090399 -0.064240  \n",
       "count3                 -0.082684 -0.075494 -0.085048 -0.094629 -0.067246  \n",
       "count4                 -0.081480 -0.074396 -0.083810 -0.093251 -0.066267  \n",
       "count5                 -0.074661 -0.068169 -0.076796 -0.085447 -0.060721  \n",
       "count6                 -0.073289 -0.066917 -0.075385 -0.083877 -0.059605  \n",
       "count7                 -0.084018 -0.076713 -0.086420 -0.096156 -0.068331  \n",
       "count8                 -0.059471 -0.054300 -0.061172 -0.068063 -0.048367  \n",
       "count9                 -0.039251 -0.035839 -0.040374 -0.044922 -0.031923  \n",
       "count10                -0.070843 -0.064684 -0.072869 -0.081078 -0.057616  \n",
       "count11                 1.000000 -0.067963 -0.076564 -0.085189 -0.060538  \n",
       "count12                -0.067963  1.000000 -0.069907 -0.077782 -0.055274  \n",
       "count13                -0.076564 -0.069907  1.000000 -0.087625 -0.062269  \n",
       "count14                -0.085189 -0.077782 -0.087625  1.000000 -0.069283  \n",
       "count15                -0.060538 -0.055274 -0.062269 -0.069283  1.000000  \n",
       "\n",
       "[33 rows x 33 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrMatrix = df.corr()\n",
    "corrMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting into Training and Testing set\n",
    "We split data in 80-20 proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalisation(arr):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    return (arr - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "data = df.to_numpy()\n",
    "X, y = data[:,1:], data[:,0]\n",
    "\n",
    "y_norm = min_max_normalisation(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, X, y, file_name):\n",
    "    model.fit(X, y)\n",
    "    pickle.dump(model, open(file_name, 'wb'))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(model, X, y, iterations):\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    for i in range(iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_test = model.predict(X_test)\n",
    "        result_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "        \n",
    "        y_pred_train = model.predict(X_train)\n",
    "        result_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    return np.mean(result_train)*100, np.mean(result_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new, y_new = get_train_test_data(X, y, 20)\n",
    "X_new, y_new = X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  57.10554708501569\n",
      "testing data:  57.52430589435302\n"
     ]
    }
   ],
   "source": [
    "model_linear = linear_model.LinearRegression()\n",
    "train, test = model_testing(model_linear, X_new, y_new, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "file_name = \"trained_models/lin_reg.pickle\"\n",
    "save_model(model, X, y, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 90}\n"
     ]
    }
   ],
   "source": [
    "ridge_params = {'alpha':[100, 95, 90, 85, 80, 70]}\n",
    "model_ridge = GridSearchCV(linear_model.Ridge(), param_grid = ridge_params, cv = 5).fit(X_new, y_new)\n",
    "print(model_ridge.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  57.10556883045832\n",
      "testing data:  57.5245007818703\n"
     ]
    }
   ],
   "source": [
    "final_ridge_params = {\n",
    "    'alpha': 90\n",
    "}\n",
    "model_ridge_final = linear_model.Ridge(**final_ridge_params)\n",
    "train, test = model_testing(model_ridge, X_new, y_new, 10)\n",
    "\n",
    "file_name = \"trained_models/lin_ridge.pickle\"\n",
    "save_model(model, X, y, file_name)\n",
    "\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  45.936444532369705\n",
      "testing data:  47.18400908325359\n"
     ]
    }
   ],
   "source": [
    "mlp_params = {\n",
    "    'max_iter': 1000,\n",
    "    'hidden_layer_sizes': (30,),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate_init': 0.0009,\n",
    "    'learning_rate': 'constant'\n",
    "}\n",
    "\n",
    "model_mlp_base = MLPRegressor(**mlp_params)\n",
    "train, test = model_testing(model_mlp_base, X[:150000,:], y[:150000,], 1)\n",
    "# train, test = model_testing(model_mlp_base, X, y, 1)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Grid Search to find best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'hidden_layer_sizes': (30,), 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/users/shivam/.conda/envs/venv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "mlp_space1 = {\n",
    "    'hidden_layer_sizes': [(40,), (20,), (30,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "#     'learning_rate': ['constant'],\n",
    "#     'batch_size': ['auto'],\n",
    "}\n",
    "\n",
    "model_mlp_grid1 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space1, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "print(model_mlp_grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 'auto', 'hidden_layer_sizes': (35,), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# mlp_space1 = {\n",
    "#     'hidden_layer_sizes': [(25,), (30,), (35,)],\n",
    "#     'activation': ['relu', 'tanh'],\n",
    "#     'solver': ['adam'],\n",
    "#     'learning_rate': ['constant'],\n",
    "#     'batch_size': ['auto'],\n",
    "# }\n",
    "\n",
    "# model_mlp_grid1 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space1, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "# print(model_mlp_grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.001, 'batch_size': 'auto', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0005, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp_space2 = {\n",
    "    'hidden_layer_sizes': [(35,), (50,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.001, 0.005],\n",
    "    'learning_rate': ['constant'],\n",
    "    'learning_rate_init': [0.0005, 0.0001],\n",
    "    'batch_size': ['auto'],\n",
    "}\n",
    "\n",
    "model_mlp_grid2 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space2, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "print(model_mlp_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.001, 'batch_size': 'auto', 'hidden_layer_sizes': (80,), 'learning_rate': 'constant', 'learning_rate_init': 0.0005, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp_space2 = {\n",
    "    'hidden_layer_sizes': [(35,), (50,), (80,), (100,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.001],\n",
    "    'learning_rate': ['constant'],\n",
    "    'learning_rate_init': [0.0005],\n",
    "    'batch_size': ['auto'],\n",
    "}\n",
    "\n",
    "model_mlp_grid2 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space2, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "print(model_mlp_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with Final Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_final_params = {\n",
    "    'max_iter': 1000,\n",
    "    'hidden_layer_sizes': (80,),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate_init': 0.0005,\n",
    "    'learning_rate': 'constant'\n",
    "}\n",
    "\n",
    "model_mlp_base = MLPRegressor(**mlp_params)\n",
    "train, test = model_testing(model_mlp_base, X, y, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  15.79908888301264\n",
      "testing data:  36.89598287355623\n"
     ]
    }
   ],
   "source": [
    "rand_params = {\n",
    "    \"n_estimators\" : 40,\n",
    "    \"max_features\" : 'auto',\n",
    "    \"max_depth\" : 30,\n",
    "    \"min_samples_split\" : 3,\n",
    "    \"min_samples_leaf\" : 1\n",
    "}\n",
    "\n",
    "model_random1 = RandomForestRegressor(**rand_params)\n",
    "train, test = model_testing(model_random1, X[:100000,:], y[:100000,], 1)\n",
    "# train, test = model_testing(model_random1, X, y, 1)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hyperparameters using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "random_params = {\n",
    "    'n_estimators': [15],\n",
    "#     'max_features': ['sqrt', 'auto'],\n",
    "#     'max_depth': [30, 40, 50],\n",
    "}\n",
    "\n",
    "model_random2 = GridSearchCV(RandomForestRegressor(), random_params, cv = 5).fit(X[:100000,:], y[:100000,])\n",
    "print(model_random2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 40, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "random_params = {\n",
    "    'n_estimators': [15, 20],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth': [40],\n",
    "    'min_samples_split': [3, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "model_random2 = GridSearchCV(RandomForestRegressor(), random_params, cv = 5).fit(X[:100000,:], y[:100000,])\n",
    "print(model_random2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with Final Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  0.14329873827811637\n",
      "testing data:  0.2882599974775974\n"
     ]
    }
   ],
   "source": [
    "rand_params = {\n",
    "    \"n_estimators\" : 15,\n",
    "    \"max_features\" : 'auto',\n",
    "    \"max_depth\" : 40,\n",
    "    \"min_samples_split\" : 5,\n",
    "    \"min_samples_leaf\" : 2\n",
    "}\n",
    "\n",
    "model_random3 = RandomForestRegressor(**rand_params)\n",
    "train, test = model_testing(model_random3, X, y, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "err = mean_squared_error(y_test, y_pred)\n",
    "print(np.sqrt(err)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediiction of test data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pickle.load(open(\"trained_models/lin_reg.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"data/training_data_with_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/testing_data_with_features.csv\")\n",
    "X_predict = test_data[[\"norm_views\", \"norm_comments\", \"norm_user_views\", \"norm_user_comments\",\n",
    "               \"norm_country_views\", \"norm_country_comments\", \"norm_category_views\", \"norm_category_comments\", \n",
    "               \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\", \"count1\", \"count2\", \n",
    "               \"count3\", \"count4\", \"count5\", \"count6\", \"count7\", \"count8\", \"count9\", \"count10\", \"count11\", \n",
    "               \"count12\", \"count13\", \"count14\", \"count15\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = final_model.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(training_data[\"#likes\"].to_numpy())\n",
    "y_std = np.std(training_data[\"#likes\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"#likes\"] = np.abs(y_std*y_predict + y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_data = test_data[[\"post_id\", \"user_id\", \"country\", \"category\", \"#views\", \"#comments\", \"#likes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "      <th>#views</th>\n",
       "      <th>#comments</th>\n",
       "      <th>#likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>158541.000000</td>\n",
       "      <td>158541.000000</td>\n",
       "      <td>158541.000000</td>\n",
       "      <td>1.585410e+05</td>\n",
       "      <td>1.585410e+05</td>\n",
       "      <td>1.585410e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>264527.946128</td>\n",
       "      <td>20965.922172</td>\n",
       "      <td>6.703704</td>\n",
       "      <td>5.128431e+05</td>\n",
       "      <td>2.033359e+03</td>\n",
       "      <td>2.412965e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>152467.591423</td>\n",
       "      <td>12096.910208</td>\n",
       "      <td>4.425441</td>\n",
       "      <td>1.716672e+06</td>\n",
       "      <td>1.195880e+04</td>\n",
       "      <td>7.598570e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.790670e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>132600.000000</td>\n",
       "      <td>10474.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.228000e+04</td>\n",
       "      <td>2.030000e+02</td>\n",
       "      <td>3.469572e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>264590.000000</td>\n",
       "      <td>21108.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.606290e+05</td>\n",
       "      <td>5.700000e+02</td>\n",
       "      <td>9.537753e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>396413.000000</td>\n",
       "      <td>31457.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.342040e+05</td>\n",
       "      <td>1.534000e+03</td>\n",
       "      <td>2.297921e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>528455.000000</td>\n",
       "      <td>41772.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.751551e+08</td>\n",
       "      <td>1.219528e+06</td>\n",
       "      <td>5.932230e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             post_id        user_id        country        #views  \\\n",
       "count  158541.000000  158541.000000  158541.000000  1.585410e+05   \n",
       "mean   264527.946128   20965.922172       6.703704  5.128431e+05   \n",
       "std    152467.591423   12096.910208       4.425441  1.716672e+06   \n",
       "min         5.000000       0.000000       0.000000  1.400000e+01   \n",
       "25%    132600.000000   10474.000000       3.000000  6.228000e+04   \n",
       "50%    264590.000000   21108.000000       6.000000  1.606290e+05   \n",
       "75%    396413.000000   31457.000000      11.000000  4.342040e+05   \n",
       "max    528455.000000   41772.000000      14.000000  1.751551e+08   \n",
       "\n",
       "          #comments        #likes  \n",
       "count  1.585410e+05  1.585410e+05  \n",
       "mean   2.033359e+03  2.412965e+04  \n",
       "std    1.195880e+04  7.598570e+04  \n",
       "min    0.000000e+00  5.790670e-02  \n",
       "25%    2.030000e+02  3.469572e+03  \n",
       "50%    5.700000e+02  9.537753e+03  \n",
       "75%    1.534000e+03  2.297921e+04  \n",
       "max    1.219528e+06  5.932230e+06  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_data.to_csv(\"final_likes_prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
