{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import mixture\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 369920 entries, 0 to 369919\n",
      "Data columns (total 33 columns):\n",
      "norm_likes               369920 non-null float64\n",
      "norm_views               369920 non-null float64\n",
      "norm_comments            369920 non-null float64\n",
      "user_avg_views           369920 non-null float64\n",
      "user_avg_comments        369920 non-null float64\n",
      "country_avg_views        369920 non-null float64\n",
      "country_avg_comments     369920 non-null float64\n",
      "category_avg_views       369920 non-null float64\n",
      "category_avg_comments    369920 non-null float64\n",
      "cat1                     369920 non-null float64\n",
      "cat2                     369920 non-null float64\n",
      "cat3                     369920 non-null float64\n",
      "cat4                     369920 non-null float64\n",
      "cat5                     369920 non-null float64\n",
      "cat6                     369920 non-null float64\n",
      "cat7                     369920 non-null float64\n",
      "cat8                     369920 non-null float64\n",
      "cat9                     369920 non-null float64\n",
      "count1                   369920 non-null float64\n",
      "count2                   369920 non-null float64\n",
      "count3                   369920 non-null float64\n",
      "count4                   369920 non-null float64\n",
      "count5                   369920 non-null float64\n",
      "count6                   369920 non-null float64\n",
      "count7                   369920 non-null float64\n",
      "count8                   369920 non-null float64\n",
      "count9                   369920 non-null float64\n",
      "count10                  369920 non-null float64\n",
      "count11                  369920 non-null float64\n",
      "count12                  369920 non-null float64\n",
      "count13                  369920 non-null float64\n",
      "count14                  369920 non-null float64\n",
      "count15                  369920 non-null float64\n",
      "dtypes: float64(33)\n",
      "memory usage: 93.1 MB\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"data/training_data_with_features.csv\")\n",
    "df = all_data[[\"norm_likes\", \"norm_views\", \"norm_comments\", \"user_avg_views\", \"user_avg_comments\",\n",
    "               \"country_avg_views\", \"country_avg_comments\", \"category_avg_views\", \"category_avg_comments\", \n",
    "               \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat7\", \"cat8\", \"cat9\", \"count1\", \"count2\", \n",
    "               \"count3\", \"count4\", \"count5\", \"count6\", \"count7\", \"count8\", \"count9\", \"count10\", \"count11\", \n",
    "               \"count12\", \"count13\", \"count14\", \"count15\"]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_likes</th>\n",
       "      <th>norm_views</th>\n",
       "      <th>norm_comments</th>\n",
       "      <th>user_avg_views</th>\n",
       "      <th>user_avg_comments</th>\n",
       "      <th>country_avg_views</th>\n",
       "      <th>country_avg_comments</th>\n",
       "      <th>category_avg_views</th>\n",
       "      <th>category_avg_comments</th>\n",
       "      <th>cat1</th>\n",
       "      <th>...</th>\n",
       "      <th>count6</th>\n",
       "      <th>count7</th>\n",
       "      <th>count8</th>\n",
       "      <th>count9</th>\n",
       "      <th>count10</th>\n",
       "      <th>count11</th>\n",
       "      <th>count12</th>\n",
       "      <th>count13</th>\n",
       "      <th>count14</th>\n",
       "      <th>count15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>norm_likes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696550</td>\n",
       "      <td>0.796899</td>\n",
       "      <td>0.595414</td>\n",
       "      <td>0.730856</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.026466</td>\n",
       "      <td>0.203681</td>\n",
       "      <td>0.214465</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014923</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>-0.009089</td>\n",
       "      <td>0.012283</td>\n",
       "      <td>-0.011157</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>-0.007898</td>\n",
       "      <td>-0.006249</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.023148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_views</td>\n",
       "      <td>0.696550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491115</td>\n",
       "      <td>0.772156</td>\n",
       "      <td>0.406799</td>\n",
       "      <td>0.072709</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.199067</td>\n",
       "      <td>0.182939</td>\n",
       "      <td>-0.044912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017495</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.028117</td>\n",
       "      <td>-0.008319</td>\n",
       "      <td>-0.012711</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.029926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>norm_comments</td>\n",
       "      <td>0.796899</td>\n",
       "      <td>0.491115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400587</td>\n",
       "      <td>0.760364</td>\n",
       "      <td>0.032449</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.109967</td>\n",
       "      <td>0.119661</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013678</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.022843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>user_avg_views</td>\n",
       "      <td>0.595414</td>\n",
       "      <td>0.772156</td>\n",
       "      <td>0.400587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526835</td>\n",
       "      <td>0.094994</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.246069</td>\n",
       "      <td>0.224230</td>\n",
       "      <td>-0.057025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025830</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.045805</td>\n",
       "      <td>-0.015947</td>\n",
       "      <td>-0.013810</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.035591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>user_avg_comments</td>\n",
       "      <td>0.730856</td>\n",
       "      <td>0.406799</td>\n",
       "      <td>0.760364</td>\n",
       "      <td>0.526835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044424</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>0.140571</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018301</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>-0.014786</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>-0.010362</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>0.029741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>country_avg_views</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.072709</td>\n",
       "      <td>0.032449</td>\n",
       "      <td>0.094994</td>\n",
       "      <td>0.044424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831717</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-0.018379</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240617</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.386710</td>\n",
       "      <td>-0.114408</td>\n",
       "      <td>-0.174823</td>\n",
       "      <td>0.093278</td>\n",
       "      <td>0.086284</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>0.411581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>country_avg_comments</td>\n",
       "      <td>0.026466</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.831717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016384</td>\n",
       "      <td>-0.013190</td>\n",
       "      <td>0.038470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350592</td>\n",
       "      <td>0.105110</td>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>-0.246553</td>\n",
       "      <td>-0.017257</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>-0.154709</td>\n",
       "      <td>0.236287</td>\n",
       "      <td>0.585511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category_avg_views</td>\n",
       "      <td>0.203681</td>\n",
       "      <td>0.199067</td>\n",
       "      <td>0.109967</td>\n",
       "      <td>0.246069</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-0.016384</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918981</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>-0.021173</td>\n",
       "      <td>-0.010832</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>-0.017429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>category_avg_comments</td>\n",
       "      <td>0.214465</td>\n",
       "      <td>0.182939</td>\n",
       "      <td>0.119661</td>\n",
       "      <td>0.224230</td>\n",
       "      <td>0.140571</td>\n",
       "      <td>-0.018379</td>\n",
       "      <td>-0.013190</td>\n",
       "      <td>0.918981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>-0.014449</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>-0.010916</td>\n",
       "      <td>-0.031923</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat1</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.044912</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>-0.057025</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>0.038470</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>-0.024798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>-0.052085</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>-0.007131</td>\n",
       "      <td>-0.021783</td>\n",
       "      <td>0.043657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat2</td>\n",
       "      <td>-0.055190</td>\n",
       "      <td>-0.032655</td>\n",
       "      <td>-0.034095</td>\n",
       "      <td>-0.037553</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-0.023572</td>\n",
       "      <td>-0.029578</td>\n",
       "      <td>-0.164037</td>\n",
       "      <td>-0.284930</td>\n",
       "      <td>-0.146492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>-0.013166</td>\n",
       "      <td>-0.025945</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>-0.008480</td>\n",
       "      <td>0.022795</td>\n",
       "      <td>-0.021479</td>\n",
       "      <td>-0.011499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat3</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.040132</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.046193</td>\n",
       "      <td>0.023716</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.201598</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>-0.243624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.018349</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.053921</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>-0.032077</td>\n",
       "      <td>0.019114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat4</td>\n",
       "      <td>-0.046950</td>\n",
       "      <td>-0.047169</td>\n",
       "      <td>-0.024698</td>\n",
       "      <td>-0.053791</td>\n",
       "      <td>-0.031397</td>\n",
       "      <td>-0.045655</td>\n",
       "      <td>-0.024535</td>\n",
       "      <td>-0.236948</td>\n",
       "      <td>-0.206398</td>\n",
       "      <td>-0.144691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>-0.015956</td>\n",
       "      <td>-0.030836</td>\n",
       "      <td>-0.000519</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>-0.010642</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>-0.019356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat5</td>\n",
       "      <td>0.203535</td>\n",
       "      <td>0.180355</td>\n",
       "      <td>0.110375</td>\n",
       "      <td>0.224205</td>\n",
       "      <td>0.128204</td>\n",
       "      <td>-0.045325</td>\n",
       "      <td>-0.031227</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.922396</td>\n",
       "      <td>-0.078840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>-0.014487</td>\n",
       "      <td>-0.026006</td>\n",
       "      <td>0.028392</td>\n",
       "      <td>-0.021186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat6</td>\n",
       "      <td>-0.025402</td>\n",
       "      <td>-0.017334</td>\n",
       "      <td>-0.014694</td>\n",
       "      <td>-0.017791</td>\n",
       "      <td>-0.017478</td>\n",
       "      <td>-0.040477</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>-0.087078</td>\n",
       "      <td>-0.122793</td>\n",
       "      <td>-0.105629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>-0.007679</td>\n",
       "      <td>-0.024095</td>\n",
       "      <td>-0.062570</td>\n",
       "      <td>0.004047</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>-0.018009</td>\n",
       "      <td>0.061776</td>\n",
       "      <td>-0.031154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat7</td>\n",
       "      <td>-0.013148</td>\n",
       "      <td>0.034026</td>\n",
       "      <td>-0.017947</td>\n",
       "      <td>0.045216</td>\n",
       "      <td>-0.021420</td>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.019221</td>\n",
       "      <td>0.170926</td>\n",
       "      <td>-0.149979</td>\n",
       "      <td>-0.117439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024858</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>-0.020912</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>-0.015908</td>\n",
       "      <td>-0.029112</td>\n",
       "      <td>-0.019449</td>\n",
       "      <td>0.052508</td>\n",
       "      <td>0.034280</td>\n",
       "      <td>-0.029473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat8</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>-0.009250</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>-0.016562</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>0.043279</td>\n",
       "      <td>0.026147</td>\n",
       "      <td>-0.046465</td>\n",
       "      <td>0.068414</td>\n",
       "      <td>-0.177400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001940</td>\n",
       "      <td>-0.022937</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.046027</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>-0.006215</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>-0.027807</td>\n",
       "      <td>0.038528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat9</td>\n",
       "      <td>-0.023820</td>\n",
       "      <td>-0.029811</td>\n",
       "      <td>-0.010441</td>\n",
       "      <td>-0.037600</td>\n",
       "      <td>-0.013153</td>\n",
       "      <td>-0.043455</td>\n",
       "      <td>-0.033394</td>\n",
       "      <td>-0.149751</td>\n",
       "      <td>-0.087257</td>\n",
       "      <td>-0.155594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>-0.013817</td>\n",
       "      <td>-0.016599</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>-0.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count1</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>0.030613</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.038547</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.421039</td>\n",
       "      <td>0.247273</td>\n",
       "      <td>-0.008184</td>\n",
       "      <td>-0.023463</td>\n",
       "      <td>0.011913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072516</td>\n",
       "      <td>-0.083161</td>\n",
       "      <td>-0.058944</td>\n",
       "      <td>-0.039112</td>\n",
       "      <td>-0.070269</td>\n",
       "      <td>-0.073615</td>\n",
       "      <td>-0.067337</td>\n",
       "      <td>-0.075934</td>\n",
       "      <td>-0.084315</td>\n",
       "      <td>-0.060113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count2</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.020828</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>0.021950</td>\n",
       "      <td>0.017871</td>\n",
       "      <td>0.286450</td>\n",
       "      <td>0.336549</td>\n",
       "      <td>-0.025959</td>\n",
       "      <td>-0.020934</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077727</td>\n",
       "      <td>-0.089137</td>\n",
       "      <td>-0.063180</td>\n",
       "      <td>-0.041922</td>\n",
       "      <td>-0.075319</td>\n",
       "      <td>-0.078905</td>\n",
       "      <td>-0.072175</td>\n",
       "      <td>-0.081391</td>\n",
       "      <td>-0.090374</td>\n",
       "      <td>-0.064433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count3</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>-0.038788</td>\n",
       "      <td>-0.016418</td>\n",
       "      <td>-0.047807</td>\n",
       "      <td>-0.023255</td>\n",
       "      <td>-0.533469</td>\n",
       "      <td>-0.420816</td>\n",
       "      <td>-0.004276</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>-0.016573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081051</td>\n",
       "      <td>-0.092948</td>\n",
       "      <td>-0.065882</td>\n",
       "      <td>-0.043715</td>\n",
       "      <td>-0.078540</td>\n",
       "      <td>-0.082279</td>\n",
       "      <td>-0.075262</td>\n",
       "      <td>-0.084871</td>\n",
       "      <td>-0.094238</td>\n",
       "      <td>-0.067188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count4</td>\n",
       "      <td>-0.017095</td>\n",
       "      <td>-0.018924</td>\n",
       "      <td>-0.011023</td>\n",
       "      <td>-0.025835</td>\n",
       "      <td>-0.014795</td>\n",
       "      <td>-0.260266</td>\n",
       "      <td>-0.282534</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-0.020641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080059</td>\n",
       "      <td>-0.091810</td>\n",
       "      <td>-0.065075</td>\n",
       "      <td>-0.043180</td>\n",
       "      <td>-0.077578</td>\n",
       "      <td>-0.081271</td>\n",
       "      <td>-0.074340</td>\n",
       "      <td>-0.083832</td>\n",
       "      <td>-0.093084</td>\n",
       "      <td>-0.066365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count5</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>-0.009667</td>\n",
       "      <td>-0.003818</td>\n",
       "      <td>-0.015482</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>-0.132960</td>\n",
       "      <td>-0.097867</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073433</td>\n",
       "      <td>-0.084212</td>\n",
       "      <td>-0.059690</td>\n",
       "      <td>-0.039606</td>\n",
       "      <td>-0.071158</td>\n",
       "      <td>-0.074545</td>\n",
       "      <td>-0.068188</td>\n",
       "      <td>-0.076894</td>\n",
       "      <td>-0.085381</td>\n",
       "      <td>-0.060873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count6</td>\n",
       "      <td>-0.014923</td>\n",
       "      <td>-0.017495</td>\n",
       "      <td>-0.013678</td>\n",
       "      <td>-0.025830</td>\n",
       "      <td>-0.018301</td>\n",
       "      <td>-0.240617</td>\n",
       "      <td>-0.350592</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.013354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082582</td>\n",
       "      <td>-0.058534</td>\n",
       "      <td>-0.038839</td>\n",
       "      <td>-0.069780</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>-0.066868</td>\n",
       "      <td>-0.075405</td>\n",
       "      <td>-0.083728</td>\n",
       "      <td>-0.059694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count7</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.105110</td>\n",
       "      <td>-0.005085</td>\n",
       "      <td>-0.014449</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067126</td>\n",
       "      <td>-0.044540</td>\n",
       "      <td>-0.080023</td>\n",
       "      <td>-0.083832</td>\n",
       "      <td>-0.076683</td>\n",
       "      <td>-0.086474</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>-0.068457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count8</td>\n",
       "      <td>-0.009089</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058534</td>\n",
       "      <td>-0.067126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031570</td>\n",
       "      <td>-0.056720</td>\n",
       "      <td>-0.059420</td>\n",
       "      <td>-0.054353</td>\n",
       "      <td>-0.061293</td>\n",
       "      <td>-0.068057</td>\n",
       "      <td>-0.048522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count9</td>\n",
       "      <td>0.012283</td>\n",
       "      <td>0.028117</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.045805</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.386710</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>-0.052085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038839</td>\n",
       "      <td>-0.044540</td>\n",
       "      <td>-0.031570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.039427</td>\n",
       "      <td>-0.036065</td>\n",
       "      <td>-0.040670</td>\n",
       "      <td>-0.045158</td>\n",
       "      <td>-0.032196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count10</td>\n",
       "      <td>-0.011157</td>\n",
       "      <td>-0.008319</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>-0.015947</td>\n",
       "      <td>-0.014786</td>\n",
       "      <td>-0.114408</td>\n",
       "      <td>-0.246553</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>-0.012075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069780</td>\n",
       "      <td>-0.080023</td>\n",
       "      <td>-0.056720</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070837</td>\n",
       "      <td>-0.064796</td>\n",
       "      <td>-0.073069</td>\n",
       "      <td>-0.081133</td>\n",
       "      <td>-0.057845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count11</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>-0.012711</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>-0.013810</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.174823</td>\n",
       "      <td>-0.017257</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>-0.083832</td>\n",
       "      <td>-0.059420</td>\n",
       "      <td>-0.039427</td>\n",
       "      <td>-0.070837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067880</td>\n",
       "      <td>-0.076547</td>\n",
       "      <td>-0.084996</td>\n",
       "      <td>-0.060598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count12</td>\n",
       "      <td>-0.007898</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.093278</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>-0.021173</td>\n",
       "      <td>-0.010916</td>\n",
       "      <td>0.024759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066868</td>\n",
       "      <td>-0.076683</td>\n",
       "      <td>-0.054353</td>\n",
       "      <td>-0.036065</td>\n",
       "      <td>-0.064796</td>\n",
       "      <td>-0.067880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.070019</td>\n",
       "      <td>-0.077747</td>\n",
       "      <td>-0.055430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count13</td>\n",
       "      <td>-0.006249</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>-0.010362</td>\n",
       "      <td>0.086284</td>\n",
       "      <td>-0.154709</td>\n",
       "      <td>-0.010832</td>\n",
       "      <td>-0.031923</td>\n",
       "      <td>-0.007131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075405</td>\n",
       "      <td>-0.086474</td>\n",
       "      <td>-0.061293</td>\n",
       "      <td>-0.040670</td>\n",
       "      <td>-0.073069</td>\n",
       "      <td>-0.076547</td>\n",
       "      <td>-0.070019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.087674</td>\n",
       "      <td>-0.062508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count14</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>0.236287</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>-0.021783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083728</td>\n",
       "      <td>-0.096018</td>\n",
       "      <td>-0.068057</td>\n",
       "      <td>-0.045158</td>\n",
       "      <td>-0.081133</td>\n",
       "      <td>-0.084996</td>\n",
       "      <td>-0.077747</td>\n",
       "      <td>-0.087674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>count15</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.029926</td>\n",
       "      <td>0.022843</td>\n",
       "      <td>0.035591</td>\n",
       "      <td>0.029741</td>\n",
       "      <td>0.411581</td>\n",
       "      <td>0.585511</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.043657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059694</td>\n",
       "      <td>-0.068457</td>\n",
       "      <td>-0.048522</td>\n",
       "      <td>-0.032196</td>\n",
       "      <td>-0.057845</td>\n",
       "      <td>-0.060598</td>\n",
       "      <td>-0.055430</td>\n",
       "      <td>-0.062508</td>\n",
       "      <td>-0.069407</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       norm_likes  norm_views  norm_comments  user_avg_views  \\\n",
       "norm_likes               1.000000    0.696550       0.796899        0.595414   \n",
       "norm_views               0.696550    1.000000       0.491115        0.772156   \n",
       "norm_comments            0.796899    0.491115       1.000000        0.400587   \n",
       "user_avg_views           0.595414    0.772156       0.400587        1.000000   \n",
       "user_avg_comments        0.730856    0.406799       0.760364        0.526835   \n",
       "country_avg_views        0.022556    0.072709       0.032449        0.094994   \n",
       "country_avg_comments     0.026466    0.060474       0.039014        0.079526   \n",
       "category_avg_views       0.203681    0.199067       0.109967        0.246069   \n",
       "category_avg_comments    0.214465    0.182939       0.119661        0.224230   \n",
       "cat1                     0.000386   -0.044912      -0.002967       -0.057025   \n",
       "cat2                    -0.055190   -0.032655      -0.034095       -0.037553   \n",
       "cat3                     0.025118    0.040132       0.018232        0.046193   \n",
       "cat4                    -0.046950   -0.047169      -0.024698       -0.053791   \n",
       "cat5                     0.203535    0.180355       0.110375        0.224205   \n",
       "cat6                    -0.025402   -0.017334      -0.014694       -0.017791   \n",
       "cat7                    -0.013148    0.034026      -0.017947        0.045216   \n",
       "cat8                     0.002533   -0.009250       0.008187       -0.016562   \n",
       "cat9                    -0.023820   -0.029811      -0.010441       -0.037600   \n",
       "count1                   0.013002    0.030613       0.009647        0.038547   \n",
       "count2                   0.009920    0.020828       0.013130        0.021950   \n",
       "count3                   0.009911   -0.038788      -0.016418       -0.047807   \n",
       "count4                  -0.017095   -0.018924      -0.011023       -0.025835   \n",
       "count5                   0.004174   -0.009667      -0.003818       -0.015482   \n",
       "count6                  -0.014923   -0.017495      -0.013678       -0.025830   \n",
       "count7                  -0.004728    0.000660       0.004101        0.008089   \n",
       "count8                  -0.009089    0.000306       0.001907       -0.000690   \n",
       "count9                   0.012283    0.028117       0.001671        0.045805   \n",
       "count10                 -0.011157   -0.008319      -0.009619       -0.015947   \n",
       "count11                  0.005563   -0.012711      -0.000673       -0.013810   \n",
       "count12                 -0.007898    0.006782       0.003654        0.006110   \n",
       "count13                 -0.006249    0.006274      -0.006036        0.005481   \n",
       "count14                  0.000170    0.003276       0.009219        0.012316   \n",
       "count15                  0.023148    0.029926       0.022843        0.035591   \n",
       "\n",
       "                       user_avg_comments  country_avg_views  \\\n",
       "norm_likes                      0.730856           0.022556   \n",
       "norm_views                      0.406799           0.072709   \n",
       "norm_comments                   0.760364           0.032449   \n",
       "user_avg_views                  0.526835           0.094994   \n",
       "user_avg_comments               1.000000           0.044424   \n",
       "country_avg_views               0.044424           1.000000   \n",
       "country_avg_comments            0.053561           0.831717   \n",
       "category_avg_views              0.128605          -0.008102   \n",
       "category_avg_comments           0.140571          -0.018379   \n",
       "cat1                           -0.000582           0.017794   \n",
       "cat2                           -0.042083          -0.023572   \n",
       "cat3                            0.023716           0.039700   \n",
       "cat4                           -0.031397          -0.045655   \n",
       "cat5                            0.128204          -0.045325   \n",
       "cat6                           -0.017478          -0.040477   \n",
       "cat7                           -0.021420           0.052067   \n",
       "cat8                            0.009445           0.043279   \n",
       "cat9                           -0.013153          -0.043455   \n",
       "count1                          0.010623           0.421039   \n",
       "count2                          0.017871           0.286450   \n",
       "count3                         -0.023255          -0.533469   \n",
       "count4                         -0.014795          -0.260266   \n",
       "count5                         -0.005487          -0.132960   \n",
       "count6                         -0.018301          -0.240617   \n",
       "count7                          0.009104           0.009081   \n",
       "count8                          0.001875           0.004209   \n",
       "count9                          0.006288           0.386710   \n",
       "count10                        -0.014786          -0.114408   \n",
       "count11                         0.000021          -0.174823   \n",
       "count12                         0.003992           0.093278   \n",
       "count13                        -0.010362           0.086284   \n",
       "count14                         0.014876           0.045057   \n",
       "count15                         0.029741           0.411581   \n",
       "\n",
       "                       country_avg_comments  category_avg_views  \\\n",
       "norm_likes                         0.026466            0.203681   \n",
       "norm_views                         0.060474            0.199067   \n",
       "norm_comments                      0.039014            0.109967   \n",
       "user_avg_views                     0.079526            0.246069   \n",
       "user_avg_comments                  0.053561            0.128605   \n",
       "country_avg_views                  0.831717           -0.008102   \n",
       "country_avg_comments               1.000000           -0.016384   \n",
       "category_avg_views                -0.016384            1.000000   \n",
       "category_avg_comments             -0.013190            0.918981   \n",
       "cat1                               0.038470           -0.225610   \n",
       "cat2                              -0.029578           -0.164037   \n",
       "cat3                               0.012042            0.201598   \n",
       "cat4                              -0.024535           -0.236948   \n",
       "cat5                              -0.031227            0.906000   \n",
       "cat6                              -0.004511           -0.087078   \n",
       "cat7                               0.019221            0.170926   \n",
       "cat8                               0.026147           -0.046465   \n",
       "cat9                              -0.033394           -0.149751   \n",
       "count1                             0.247273           -0.008184   \n",
       "count2                             0.336549           -0.025959   \n",
       "count3                            -0.420816           -0.004276   \n",
       "count4                            -0.282534            0.007256   \n",
       "count5                            -0.097867            0.005302   \n",
       "count6                            -0.350592            0.000888   \n",
       "count7                             0.105110           -0.005085   \n",
       "count8                             0.048889            0.016766   \n",
       "count9                             0.042837            0.035846   \n",
       "count10                           -0.246553            0.008237   \n",
       "count11                           -0.017257            0.009950   \n",
       "count12                            0.093662           -0.021173   \n",
       "count13                           -0.154709           -0.010832   \n",
       "count14                            0.236287            0.022621   \n",
       "count15                            0.585511           -0.017429   \n",
       "\n",
       "                       category_avg_comments      cat1  ...    count6  \\\n",
       "norm_likes                          0.214465  0.000386  ... -0.014923   \n",
       "norm_views                          0.182939 -0.044912  ... -0.017495   \n",
       "norm_comments                       0.119661 -0.002967  ... -0.013678   \n",
       "user_avg_views                      0.224230 -0.057025  ... -0.025830   \n",
       "user_avg_comments                   0.140571 -0.000582  ... -0.018301   \n",
       "country_avg_views                  -0.018379  0.017794  ... -0.240617   \n",
       "country_avg_comments               -0.013190  0.038470  ... -0.350592   \n",
       "category_avg_views                  0.918981 -0.225610  ...  0.000888   \n",
       "category_avg_comments               1.000000 -0.024798  ...  0.010960   \n",
       "cat1                               -0.024798  1.000000  ...  0.013354   \n",
       "cat2                               -0.284930 -0.146492  ...  0.005936   \n",
       "cat3                                0.152361 -0.243624  ... -0.005759   \n",
       "cat4                               -0.206398 -0.144691  ...  0.009515   \n",
       "cat5                                0.922396 -0.078840  ...  0.011764   \n",
       "cat6                               -0.122793 -0.105629  ... -0.012819   \n",
       "cat7                               -0.149979 -0.117439  ... -0.024858   \n",
       "cat8                                0.068414 -0.177400  ... -0.001940   \n",
       "cat9                               -0.087257 -0.155594  ...  0.002115   \n",
       "count1                             -0.023463  0.011913  ... -0.072516   \n",
       "count2                             -0.020934  0.021074  ... -0.077727   \n",
       "count3                              0.000626 -0.016573  ... -0.081051   \n",
       "count4                              0.000577 -0.020641  ... -0.080059   \n",
       "count5                              0.016746  0.009526  ... -0.073433   \n",
       "count6                              0.010960  0.013354  ...  1.000000   \n",
       "count7                             -0.014449 -0.009969  ... -0.082582   \n",
       "count8                              0.026105  0.004602  ... -0.058534   \n",
       "count9                              0.021844 -0.052085  ... -0.038839   \n",
       "count10                             0.011333 -0.012075  ... -0.069780   \n",
       "count11                             0.019334  0.003941  ... -0.073102   \n",
       "count12                            -0.010916  0.024759  ... -0.066868   \n",
       "count13                            -0.031923 -0.007131  ... -0.075405   \n",
       "count14                             0.009129 -0.021783  ... -0.083728   \n",
       "count15                             0.001464  0.043657  ... -0.059694   \n",
       "\n",
       "                         count7    count8    count9   count10   count11  \\\n",
       "norm_likes            -0.004728 -0.009089  0.012283 -0.011157  0.005563   \n",
       "norm_views             0.000660  0.000306  0.028117 -0.008319 -0.012711   \n",
       "norm_comments          0.004101  0.001907  0.001671 -0.009619 -0.000673   \n",
       "user_avg_views         0.008089 -0.000690  0.045805 -0.015947 -0.013810   \n",
       "user_avg_comments      0.009104  0.001875  0.006288 -0.014786  0.000021   \n",
       "country_avg_views      0.009081  0.004209  0.386710 -0.114408 -0.174823   \n",
       "country_avg_comments   0.105110  0.048889  0.042837 -0.246553 -0.017257   \n",
       "category_avg_views    -0.005085  0.016766  0.035846  0.008237  0.009950   \n",
       "category_avg_comments -0.014449  0.026105  0.021844  0.011333  0.019334   \n",
       "cat1                  -0.009969  0.004602 -0.052085 -0.012075  0.003941   \n",
       "cat2                  -0.001399 -0.013166 -0.025945  0.022782  0.004307   \n",
       "cat3                  -0.018349  0.018721  0.053921  0.020799 -0.005339   \n",
       "cat4                   0.017660 -0.015956 -0.030836 -0.000519  0.003039   \n",
       "cat5                  -0.001104  0.012761 -0.000238  0.005672  0.021596   \n",
       "cat6                   0.034266 -0.007679 -0.024095 -0.062570  0.004047   \n",
       "cat7                   0.019821 -0.020912  0.032085 -0.015908 -0.029112   \n",
       "cat8                  -0.022937  0.023485  0.046027  0.009423 -0.006215   \n",
       "cat9                   0.006484 -0.013817 -0.016599  0.009134  0.010693   \n",
       "count1                -0.083161 -0.058944 -0.039112 -0.070269 -0.073615   \n",
       "count2                -0.089137 -0.063180 -0.041922 -0.075319 -0.078905   \n",
       "count3                -0.092948 -0.065882 -0.043715 -0.078540 -0.082279   \n",
       "count4                -0.091810 -0.065075 -0.043180 -0.077578 -0.081271   \n",
       "count5                -0.084212 -0.059690 -0.039606 -0.071158 -0.074545   \n",
       "count6                -0.082582 -0.058534 -0.038839 -0.069780 -0.073102   \n",
       "count7                 1.000000 -0.067126 -0.044540 -0.080023 -0.083832   \n",
       "count8                -0.067126  1.000000 -0.031570 -0.056720 -0.059420   \n",
       "count9                -0.044540 -0.031570  1.000000 -0.037636 -0.039427   \n",
       "count10               -0.080023 -0.056720 -0.037636  1.000000 -0.070837   \n",
       "count11               -0.083832 -0.059420 -0.039427 -0.070837  1.000000   \n",
       "count12               -0.076683 -0.054353 -0.036065 -0.064796 -0.067880   \n",
       "count13               -0.086474 -0.061293 -0.040670 -0.073069 -0.076547   \n",
       "count14               -0.096018 -0.068057 -0.045158 -0.081133 -0.084996   \n",
       "count15               -0.068457 -0.048522 -0.032196 -0.057845 -0.060598   \n",
       "\n",
       "                        count12   count13   count14   count15  \n",
       "norm_likes            -0.007898 -0.006249  0.000170  0.023148  \n",
       "norm_views             0.006782  0.006274  0.003276  0.029926  \n",
       "norm_comments          0.003654 -0.006036  0.009219  0.022843  \n",
       "user_avg_views         0.006110  0.005481  0.012316  0.035591  \n",
       "user_avg_comments      0.003992 -0.010362  0.014876  0.029741  \n",
       "country_avg_views      0.093278  0.086284  0.045057  0.411581  \n",
       "country_avg_comments   0.093662 -0.154709  0.236287  0.585511  \n",
       "category_avg_views    -0.021173 -0.010832  0.022621 -0.017429  \n",
       "category_avg_comments -0.010916 -0.031923  0.009129  0.001464  \n",
       "cat1                   0.024759 -0.007131 -0.021783  0.043657  \n",
       "cat2                  -0.008480  0.022795 -0.021479 -0.011499  \n",
       "cat3                  -0.007042  0.001945 -0.032077  0.019114  \n",
       "cat4                  -0.008612 -0.010642  0.020822 -0.019356  \n",
       "cat5                  -0.014487 -0.026006  0.028392 -0.021186  \n",
       "cat6                   0.020080 -0.018009  0.061776 -0.031154  \n",
       "cat7                  -0.019449  0.052508  0.034280 -0.029473  \n",
       "cat8                  -0.002519 -0.010439 -0.027807  0.038528  \n",
       "cat9                   0.008466 -0.008714  0.012692 -0.032470  \n",
       "count1                -0.067337 -0.075934 -0.084315 -0.060113  \n",
       "count2                -0.072175 -0.081391 -0.090374 -0.064433  \n",
       "count3                -0.075262 -0.084871 -0.094238 -0.067188  \n",
       "count4                -0.074340 -0.083832 -0.093084 -0.066365  \n",
       "count5                -0.068188 -0.076894 -0.085381 -0.060873  \n",
       "count6                -0.066868 -0.075405 -0.083728 -0.059694  \n",
       "count7                -0.076683 -0.086474 -0.096018 -0.068457  \n",
       "count8                -0.054353 -0.061293 -0.068057 -0.048522  \n",
       "count9                -0.036065 -0.040670 -0.045158 -0.032196  \n",
       "count10               -0.064796 -0.073069 -0.081133 -0.057845  \n",
       "count11               -0.067880 -0.076547 -0.084996 -0.060598  \n",
       "count12                1.000000 -0.070019 -0.077747 -0.055430  \n",
       "count13               -0.070019  1.000000 -0.087674 -0.062508  \n",
       "count14               -0.077747 -0.087674  1.000000 -0.069407  \n",
       "count15               -0.055430 -0.062508 -0.069407  1.000000  \n",
       "\n",
       "[33 rows x 33 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrMatrix = df.corr()\n",
    "corrMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting into Training and Testing set\n",
    "We split data in 80-20 proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "data = df.to_numpy()\n",
    "X, y = data[:,1:], data[:,0]\n",
    "\n",
    "def get_train_test_data(X, y, k):\n",
    "    if k == -1:\n",
    "        return X, y\n",
    "    else:\n",
    "        test = SelectKBest(score_func=f_classif, k=k)\n",
    "        fit = test.fit(X, y)\n",
    "        X_new = fit.transform(X)\n",
    "        return X_new, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(model, X, y, iterations):\n",
    "    result_train = []\n",
    "    result_test = []\n",
    "    for i in range(iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_test = model.predict(X_test)\n",
    "        result_test.append(np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "        \n",
    "        y_pred_train = model.predict(X_train)\n",
    "        result_train.append(np.sqrt(mean_squared_error(y_train, y_pred_train)))\n",
    "    return np.mean(result_train)*100, np.mean(result_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new, y_new = get_train_test_data(X, y, 20)\n",
    "X_new, y_new = get_train_test_data(X, y, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  0.6270885456952023\n",
      "testing data:  0.6502721409366095\n"
     ]
    }
   ],
   "source": [
    "model_linear = linear_model.LinearRegression()\n",
    "train, test = model_testing(model_linear, X_new, y_new, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model - Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2}\n",
      "training data:  0.6271068080850473\n",
      "testing data:  0.6505486799653135\n"
     ]
    }
   ],
   "source": [
    "ridge_params = {'alpha':[0.4, 0.3, 0.25, 0.22, 0.2, 0.18, 0.15, 0.1]}\n",
    "model_ridge = GridSearchCV(linear_model.Ridge(), param_grid = ridge_params, cv = 5).fit(X_new, y_new)\n",
    "\n",
    "print(model_ridge.best_params_)\n",
    "\n",
    "train, test = model_testing(model_ridge, X_new, y_new, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  0.6169007956159719\n",
      "testing data:  0.6634405697645084\n"
     ]
    }
   ],
   "source": [
    "mlp_params = {\n",
    "    'max_iter': 1000,\n",
    "    'hidden_layer_sizes': (30,),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate_init': 0.0009,\n",
    "    'learning_rate': 'constant'\n",
    "}\n",
    "\n",
    "model_mlp_base = MLPRegressor(**mlp_params)\n",
    "# train, test = model_testing(model_mlp, X[:150000,:], y[:150000,], 1)\n",
    "train, test = model_testing(model_mlp_base, X, y, 1)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Grid Search to find best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'batch_size': 'auto', 'hidden_layer_sizes': (35,), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp_space1 = {\n",
    "    'hidden_layer_sizes': [(25,), (30,), (35,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'learning_rate': ['constant'],\n",
    "    'batch_size': ['auto'],\n",
    "}\n",
    "\n",
    "model_mlp_grid1 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space1, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "print(model_mlp_grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.001, 'batch_size': 'auto', 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0005, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp_space2 = {\n",
    "    'hidden_layer_sizes': [(35,), (50,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.001, 0.005],\n",
    "    'learning_rate': ['constant'],\n",
    "    'learning_rate_init': [0.0005, 0.0001],\n",
    "    'batch_size': ['auto'],\n",
    "}\n",
    "\n",
    "model_mlp_grid2 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space2, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "print(model_mlp_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.001, 'batch_size': 'auto', 'hidden_layer_sizes': (80,), 'learning_rate': 'constant', 'learning_rate_init': 0.0005, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp_space2 = {\n",
    "    'hidden_layer_sizes': [(35,), (50,), (80,), (100,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.001],\n",
    "    'learning_rate': ['constant'],\n",
    "    'learning_rate_init': [0.0005],\n",
    "    'batch_size': ['auto'],\n",
    "}\n",
    "\n",
    "model_mlp_grid2 = GridSearchCV(MLPRegressor(max_iter=1000), mlp_space2, cv = 3).fit(X[:100000,:], y[:100000,])\n",
    "print(model_mlp_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with Final Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_final_params = {\n",
    "    'max_iter': 1000,\n",
    "    'hidden_layer_sizes': (80,),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate_init': 0.0005,\n",
    "    'learning_rate': 'constant'\n",
    "}\n",
    "\n",
    "model_mlp_base = MLPRegressor(**mlp_params)\n",
    "train, test = model_testing(model_mlp_base, X, y, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  0.11991251236725797\n",
      "testing data:  0.27683596326297016\n"
     ]
    }
   ],
   "source": [
    "rand_params = {\n",
    "    \"n_estimators\" : 10,\n",
    "    \"max_features\" : 'auto',\n",
    "    \"max_depth\" : 30,\n",
    "    \"min_samples_split\" : 3,\n",
    "    \"min_samples_leaf\" : 1\n",
    "}\n",
    "\n",
    "model_random1 = RandomForestRegressor(**rand_params)\n",
    "# train, test = model_testing(model_random, X[:150000,:], y[:150000,], 1)\n",
    "train, test = model_testing(model_random1, X, y, 1)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Hyperparameters using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 40, 'max_features': 'auto', 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "random_params = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_features': ['sqrt', 'auto'],\n",
    "    'max_depth': [30, 40, 50],\n",
    "}\n",
    "\n",
    "model_random2 = GridSearchCV(RandomForestRegressor(), random_params, cv = 5).fit(X[:100000,:], y[:100000,])\n",
    "print(model_random2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 40, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "random_params = {\n",
    "    'n_estimators': [15, 20],\n",
    "    'max_features': ['auto'],\n",
    "    'max_depth': [40],\n",
    "    'min_samples_split': [3, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "model_random2 = GridSearchCV(RandomForestRegressor(), random_params, cv = 5).fit(X[:100000,:], y[:100000,])\n",
    "print(model_random2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with Final Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  0.14329873827811637\n",
      "testing data:  0.2882599974775974\n"
     ]
    }
   ],
   "source": [
    "rand_params = {\n",
    "    \"n_estimators\" : 15,\n",
    "    \"max_features\" : 'auto',\n",
    "    \"max_depth\" : 40,\n",
    "    \"min_samples_split\" : 5,\n",
    "    \"min_samples_leaf\" : 2\n",
    "}\n",
    "\n",
    "model_random3 = RandomForestRegressor(**rand_params)\n",
    "train, test = model_testing(model_random3, X, y, 10)\n",
    "print(\"training data: \", train)\n",
    "print(\"testing data: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "err = mean_squared_error(y_test, y_pred)\n",
    "print(np.sqrt(err)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
